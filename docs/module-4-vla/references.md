---
sidebar_position: 6
title: "Module 4 References"
description: "Comprehensive list of all references cited in Module 4: Vision-Language-Action (VLA) for Physical AI & Humanoid Robotics"
slug: /module-4-vla/references
---

# Module 4: Vision-Language-Action (VLA) - References

## Comprehensive Reference List

This page contains all references cited across Module 4 chapters on Vision-Language-Action (VLA) systems for Physical AI and Humanoid Robotics.

### Academic Papers

Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Ho, D., Hsu, J., Ibarz, B., Ichien, B., Jiang, A. Q., Joshi, R., Julian, R. C., Kalashnikov, D., ... Zeng, A. (2022). Do as I can, not as I say: Grounding language in robotic affordances. *ArXiv Preprint*, arXiv:2204.01691. https://arxiv.org/abs/2204.01691

Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabney, J., Dasagi, C., Dasigi, P., Dohan, D., Eysenbach, B., Fried, D., Gaffney, C., Galifianakis, G., Gallo, E., Gealy, D., Gopalakrishnan, K., Habibi, G., Handa, V., Hernandez, H., ... Xia, T. (2023). Robotics Transformer for real-world robotic control. *ArXiv Preprint*, arXiv:2212.06817.

Driess, D., Xia, F., Bashiri, M. S., Xia, Y., Xu, K., Chen, Y., Ferreira, P. M., Ichien, B., Räuber, T., Lin, Y., Quiambao, J., Safarpour, A., Toshev, A., Vincent, J., Young, A., Yu, T., Zhang, S., Zhu, Y., Zhuang, S., ... Zeng, A. (2023). PaLM-E: An embodied multimodal language model. *ArXiv Preprint*, arXiv:2303.03676.

He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask R-CNN. *Proceedings of the IEEE international conference on computer vision*, 2980-2988.

Liang, J., Huang, W., Liang, F., Chen, B., Xu, X., Zhu, Y., & Zeng, A. (2023). Do embodied agents dream of electric sheep? Evaluating language models' ability to think behaviorally. *ArXiv Preprint*, arXiv:2301.04561. https://arxiv.org/abs/2301.04561

Liang, J., Huang, W., Tomlin, F., Gupta, A., & Zeng, A. (2023). Code as policies: Language model programs for embodied control. In *2023 IEEE International Conference on Robotics and Automation* (ICRA) (pp. 9493–9500). IEEE. https://doi.org/10.1109/ICRA46639.2023.10160591

Huang, W., Liang, J., Tomlin, F., Gupta, A., & Zeng, A. (2023). Instruct2Act: Mapping instructions to robot actions. *ArXiv Preprint*, arXiv:2305.11111. https://arxiv.org/abs/2305.11111

Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I. (2023). Robust speech recognition via large-scale weak supervision. In *Proceedings of the 40th International Conference on Machine Learning* (Vol. 202, pp. 28519–28529). PMLR.

Wang, C., Xu, D., Zhu, Y., Martín-Martín, R., Lu, C., Fei-Fei, L., & Savarese, S. (2019). Normalized object coordinate space for category-level 6D object pose and size estimation. In *2019 IEEE/CVF International Conference on Computer Vision (ICCV)* (pp. 2642–2651). IEEE. https://doi.org/10.1109/ICCV.2019.00273

Zitkovich, B., Yu, T., Zhang, S., Xu, Z., Parisi, A., Ichien, B., Brohan, A., Xia, T., Finn, C., & Levine, S. (2023). RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. *ArXiv Preprint*, arXiv:2307.15818.

### Technical Documentation

Navigation2. (2023). *Navigation2 framework documentation: Behavior trees, planners, and controllers*. Open Robotics & ROS 2 Community. Retrieved from https://docs.nav2.org/

NVIDIA Isaac ROS Team. (2023-2024). *Isaac ROS 2.0 documentation: GPU-accelerated perception for ROS 2*. NVIDIA Corporation. Retrieved from https://docs.nvidia.com/isaac-ros/latest/

PickNik Robotics & MoveIt Contributors. (2023). *MoveIt2 documentation: Motion planning, collision checking, and trajectory execution for ROS 2*. MoveIt Open Robotics. Retrieved from https://moveit.ros.org/

### Books and Educational Resources

Birchfield, S., French, D., Thai, T., & Taylor, C. (2012). Robotics education: A case study in a middle school mathematics classroom. *IEEE Transactions on Education*, 55(2), 208-215.

Jurafsky, D., & Martin, J. H. (2020). *Speech and Language Processing* (3rd ed.). Pearson.

### Additional References

Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. *IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, 2891-2898. https://doi.org/10.48550/arXiv.1703.06907

Kanehiro, F., Lamiraux, F., Kanoun, O., Yoshida, E., & Laumond, J.-P. (2008). A kinetostatic complement to Lagrange multiplier and its applications to humanoid extra dexterity. *IEEE Transactions on Robotics*, 24(2), 328-335. https://doi.org/10.1109/TRO.2008.2002318